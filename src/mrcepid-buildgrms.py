#!/usr/bin/env python
# mrcepid-collecthsmetrics 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://documentation.dnanexus.com/developer for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os
import dxpy
import subprocess
import csv
import pandas
import numpy as np


# This function runs a command on an instance, either with or without calling the docker instance we downloaded
# By default, commands are not run via Docker, but can be changed by setting is_docker = True
def run_cmd(cmd: str, is_docker: bool = False) -> None:

    if is_docker:
        # -v here mounts a local directory on an instance (in this case the home dir) to a directory internal to the
        # Docker instance named /test/. This allows us to run commands on files stored on the AWS instance within Docker
        cmd = "docker run " \
              "-v /home/dnanexus:/test " \
              "egardner413/mrcepid-associationtesting " + cmd

    # Standard python calling external commands protocol
    print(cmd)
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()

    # If the command doesn't work, print the error stream and close the AWS instance out with 'dxpy.AppError'
    if proc.returncode != 0:
        print("The following cmd failed:")
        print(cmd)
        print("STDERROR follows\n")
        print(stderr.decode('utf-8'))
        raise dxpy.AppError("Failed to run properly...")


# This is just to compartmentalise the collection of all the resources I need for this task and
# get them into the right place
def ingest_resources() -> None:

    # Ingest the UKBB plink files (this also includes relatedness and snp/sample QC files)
    dxpy.download_folder('project-G6BJF50JJv8p4PjGB9yy7YQ2',
                         'genotypes/',
                         folder = "/Bulk/Genotype Results/Genotype calls/")

    # Download a pre-computed sample IDs file.
    dxpy.download_dxfile(dxid = 'file-G6g569QJJv8XFyvb9Gf20JV7',
                         filename = "wes_samples.txt")

    # Pull wba file:
    dxpy.download_dxfile(dxid = 'file-G51V550JXk8FgfY84jXVxyqK',
                         filename = "wba.txt")


# This is a helper function to get_individuals() it
def select_related_individual(rel: pandas.DataFrame, samples_to_exclude: list) -> dict:

    # Remove individuals not in samples_to_exclude:
    rel = rel[rel['ID1'].isin(samples_to_exclude) == False]
    rel = rel[rel['ID2'].isin(samples_to_exclude) == False]

    # Get a list of related individuals:
    # This first bit makes one column of ID1 and ID2 so we can total the amount of times each individual occurs in rel
    rel_ids = [rel['ID1'], rel['ID2']]
    rel_ids = pandas.DataFrame(data = pandas.concat(rel_ids), columns = ['ID']) # and convert back into a DataFrame

    # This makes a dummy variable for each individual so that we can...
    rel_ids['dummy'] = [1] * len(rel_ids)
    # ... sum it together to count the number of times that individual appears in the list ...
    rel_totals = rel_ids.groupby('ID').agg(total = ('dummy','sum'))
    # ... and then we sort it by that value
    rel_totals = rel_totals.sort_values(by = 'total')

    return({'rel': rel, 'rel_totals': rel_totals})


# This function generates a list of related individuals and then generates various exclusions lists based on
# relatedness and ancestry
def get_individuals() -> set:

    # Get WBA individuals
    # - Need to be able to generate some separate list of individuals
    # - This is the list generated by Felix to be a bit more inclusive
    wba = set()
    wba_dict = csv.DictReader(open('wba.txt', 'r'), delimiter=" ")
    for indv in wba_dict:
        if indv['European_ancestry'] == "1":
            wba.add(str(indv['n_eid']))

    # Read overall list of individuals with WES data so we can subset the genetic data.
    wes_samp_file = open('wes_samples.txt', 'r')
    wes_samples = set()
    for eid in wes_samp_file:
        eid = eid.rstrip()
        wes_samples.add(str(eid))

    # Calculate relateds:
    # Read the relatedness file in as a pandas DataFrame
    # dtype sets eids as characters
    # ID1 and ID2 are two spearate individuals that are related according to some kinship value
    rel = pandas.read_csv("genotypes/ukb_rel.dat",
                          delim_whitespace = True,
                          dtype = {'ID1': np.str_, 'ID2': np.str_})

    # Remove individuals from the relatedness DataFrame not in WES data:
    rel = rel[rel['ID1'].isin(wes_samples)]
    rel = rel[rel['ID2'].isin(wes_samples)]

    # The relatedenss list is passed to the select_related_individuals() function for the first time so that we can
    # just calculate the number of times each individual occurs in the rel file after we limit to WES samples
    # parameter 1 is a pandas DataFrame
    # parameter 2 is a list of individuals we want to remove from parameter 1
    returned = select_related_individual(rel, []) # use an empty list first since we are just calculating totals
    rel = returned['rel']
    rel_totals = returned['rel_totals']

    relateds_to_remove = set()

    # We now iterate until we have no more related pairs in the relatedness file (rel)
    while len(rel_totals) > 0:

        # Remove the individual with the most relatedness pairs
        samp_to_remove = rel_totals.iloc[len(rel_totals) - 1].name
        relateds_to_remove.add(samp_to_remove) # and add them to the list of related individuals we want to exclude

        # And then remove that person from rel and recalculate per-individual totals and loop again
        returned = select_related_individual(rel, [samp_to_remove])
        rel = returned['rel']
        rel_totals = returned['rel_totals']

    # Get final list of WES samples to include:
    pass_samples = wes_samples.intersection(wba) # this gets WES samples that are white European ancestry
    pass_samples = pass_samples.difference(relateds_to_remove) # this gets WES samples that are white European ancestry and NOT related

    # Write exclusion lists here for WBA and relatedness and combo of the two:
    exclusion_list = open('EXCLUDEFOR_White_Euro_Relateds.txt', 'w') # list of WES non-white Euro or related individuals
    wba_exclusion_list = open('KEEPFOR_White_Euro.txt', 'w') # list of white Euro individuals with WES
    rel_exclusion_list = open('EXCLUDEFOR_Relateds.txt', 'w') # list of unrelated individuals with WES

    # This writes to each list based on a set of requirements
    for samp in wes_samples:
        if samp not in pass_samples:
            exclusion_list.write(samp + "\n")
        if samp in wba:
            wba_exclusion_list.write(samp + "\n")
        if samp in relateds_to_remove:
            rel_exclusion_list.write(samp + "\n")
    exclusion_list.close()
    wba_exclusion_list.close()
    rel_exclusion_list.close()

    return(wes_samples) ## Return a memory-stored set of samples for later


# Calculate per-snp missingness for filtering purposes:
def calculate_missingness() -> dict:

    # First generate missingness information for all SNPs:
    cmd = "plink2 --missing 'variant-only' --pfile /test/UKBB_500K_Autosomes --out /test/UKBB_500K_Autosomes"
    run_cmd(cmd, True)

    # Then read as a pandas DataFrame:
    missingness_qc = csv.DictReader(open('UKBB_500K_Autosomes.vmiss'),
                                    delimiter = "\t")
    # And convert to a dictionary with format SNP ID : missingness
    missingness = dict()
    for snp in missingness_qc:
        missingness[snp['ID']] = float(snp['F_MISS'])

    return(missingness)


# Check per-SNP and per-sample quality control
def check_QC(wes_samples: set, missingness: dict) -> None:

    # Read in UKBiobank provided quality control for SNPs
    snp_qc = csv.DictReader(open('genotypes/ukb_snp_qc.txt', 'r'), delimiter = " ")
    # Create a simple list of SNPs that pass our QC
    pass_snps = open('pass_snps.txt', 'w')

    # Generate list of the names of arrays so we can iterate through them programatically below
    array_names = []
    for x in range(1,96): # Why is range zero-based... but not?
        array_names.append("Batch_b%03d_qc" % x)
    for x in range(1, 12):
        array_names.append("UKBiLEVEAX_b%d_qc" % x)

    # And then check each SNP to make sure it is on both arrays, an autosome and has missingness < 0.05%,
    for snp in snp_qc:
        if snp['array'] == "2" and int(snp['chromosome']) <= 22 and missingness[snp['rs_id']] < 0.05:
            pass_batch_qc = True
            # Now iterate through each individual array and make sure the SNP passes there
            for array_ID in array_names:
                if snp[array_ID] != "1":
                    pass_batch_qc = False

            if pass_batch_qc == True:
                pass_snps.write(snp['rs_id'] + "\n")

    pass_snps.close()

    # Have to generate a pasted version of the sample QC file with the fam file to get useable sample IDs:
    cmd = 'paste -d " " genotypes/ukb22418_c22_b0_v2.fam genotypes/ukb_sqc_v2.txt > genotypes/ukb_sqc_v2.with_fam.txt'
    run_cmd(cmd)

    # Check sample QC files:
    # Here generating a header that mashes together the two files above
    smp_qc_header = ['ID1', 'ID2', 'null1', 'null2', 'fam.gender', 'batch1',
                     'affyID1', 'affyID2', 'array', 'batch2', 'plate', 'well',
                     'call.rate', 'dQC', 'dna.conc', 'sub.gender', 'inf.gender',
                     'x.int', 'y.int', 'plate.sub', 'well.sub', 'missing.rate',
                     'het', 'het.pc.corr', 'het.missing.outliers', 'aneuploidy', 'in.kinship',
                     'excl.kinship', 'excess.relatives', 'in.wba', 'used.pc']
    smp_qc_header.extend(["PC%d" % (item) for item in range(1,41)])
    smp_qc_header.extend(['in.phasing.auto', 'in.phasing.x', 'in.phasing.xy'])

    smp_qc = csv.DictReader(open('genotypes/ukb_sqc_v2.with_fam.txt', 'r'), delimiter = " ", fieldnames = smp_qc_header)
    # write pass IDs as a file:
    wr_file = open('samp_pass_gt_qc.txt', 'w')

    # Retain samples that are:
    # 1. In the WES samples
    # 2. Are not missingness outliers
    # 3. Are included in autosomal phasing
    for sample in smp_qc:
        if sample['ID1'] in wes_samples \
                and sample['het.missing.outliers'] == "0" \
                and sample['in.phasing.auto'] == "1":
            wr_file.write(sample['ID1'] + "\n")

    wr_file.close()


# Now apply filtering based on lists that we made above
def filter_plink() -> None:

    # Retain pass samples and pass SNPs
    cmd = "plink2 --mac 1 --pfile /test/UKBB_500K_Autosomes --make-bed --extract /test/pass_snps.txt --keep-fam /test/samp_pass_gt_qc.txt --out /test/UKBB_450K_Autosomes_QCd"
    run_cmd(cmd, True)
    # Generate a list of low MAC sites for BOLT
    cmd = "plink2 --bfile /test/UKBB_450K_Autosomes_QCd --max-mac 100 --write-snplist --out /test/UKBB_450K_Autosomes_QCd.low_MAC"
    run_cmd(cmd, True)


# SAIGE allows for precomputing a GRM to save runtime. We do that here:
def make_GRM() -> None:

    cmd = "createSparseGRM.R " \
          "--plinkFile=/test/UKBB_450K_Autosomes_QCd " \
          "--nThreads=32 " \
          "--outputPrefix=/test/sparseGRM_450K_Autosomes_QCd " \
          "--numRandomMarkerforSparseKin=2000 " \
          "--relatednessCutoff=0.125"
    run_cmd(cmd, True)


@dxpy.entry_point('main')
def main():

    # Bring our docker image into our environment so that we can run commands we need:
    cmd = "docker pull egardner413/mrcepid-associationtesting:latest"
    run_cmd(cmd)

    # Grab plink files and sample exclusion lists
    ingest_resources()

    # Merge autosomal PLINK files together:
    with open('merge_list.txt', 'w') as merge_list:
        for chr in range(1, 23):
            merge_list.write("/test/genotypes/ukb22418_c%d_b0_v2\n" % (chr))
        merge_list.close()
    cmd = "plink2 --pmerge-list /test/merge_list.txt bfile --out /test/UKBB_500K_Autosomes"
    run_cmd(cmd, True)

    # Decide on a set of individuals to extract from plink files and get per-SNP missingness:
    wes_samples = get_individuals()
    missingness = calculate_missingness()

    # Check UKB Internal SNP and Sample QC:
    check_QC(wes_samples, missingness)

    # Filter plink files to something we can use for BOLT and making GRMs
    # do not filter for WBA/Relateds, only for QC fail samples and SNPs
    filter_plink()

    # Now here we generate GRMs for tools that require it (SAIGE & STAAR):
    # BOLT and REGENIE use raw PLINK files, so do not need it here:
    make_GRM()

    ## Have to do 'upload_local_file' to make sure the new file is registered with dna nexus
    output = {'output_pgen': dxpy.dxlink(dxpy.upload_local_file('UKBB_450K_Autosomes_QCd.bed')),
              'output_psam': dxpy.dxlink(dxpy.upload_local_file('UKBB_450K_Autosomes_QCd.fam')),
              'output_pvar': dxpy.dxlink(dxpy.upload_local_file('UKBB_450K_Autosomes_QCd.bim')),
              'wba_related_filter': dxpy.dxlink(dxpy.upload_local_file('EXCLUDEFOR_White_Euro_Relateds.txt')),
              'wba_filter': dxpy.dxlink(dxpy.upload_local_file('KEEPFOR_White_Euro.txt')),
              'related_filter': dxpy.dxlink(dxpy.upload_local_file('EXCLUDEFOR_Relateds.txt')),
              'grm': dxpy.dxlink(dxpy.upload_local_file('sparseGRM_450K_Autosomes_QCd_relatednessCutoff_0.125_2000_randomMarkersUsed.sparseGRM.mtx')),
              'grm_samp': dxpy.dxlink(dxpy.upload_local_file('sparseGRM_450K_Autosomes_QCd_relatednessCutoff_0.125_2000_randomMarkersUsed.sparseGRM.mtx.sampleIDs.txt')),
              'snp_list': dxpy.dxlink(dxpy.upload_local_file('UKBB_450K_Autosomes_QCd.low_MAC.snplist'))}

    return output

dxpy.run()